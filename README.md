# AvaliaÃ§Ã£o de Ataques adversarios na detecÃ§Ã£o de emoÃ§Ãµes
Este repositÃ³rio reÃºne todo o cÃ³digo, dados e resultados do projeto de Processamento de Imagem que avalia o impacto de ataques adversariais em modelos de classificaÃ§Ã£o de expressÃµes faciais. 
Foram usados os conjuntos de dados FER-2013 e RAF-DB e testados ataques FGSM, PGD e DeepFool em modelos prÃ©-treinados e em fineâ€‘tuning adversarial.
## Membros:
- Gabriel Santos de Andrade - RA: 815407
- Leonardo Prado Silva - RA: 813169

## ðŸ“‚ Estrutura do Projeto

```
.
â”œâ”€â”€ .vscode/                       # ConfiguraÃ§Ãµes do VSCode (anÃ¡lise inicial + Îµ=1)
â”œâ”€â”€ Datasets/                      # Dados originais (FER-2013, RAF-DB)
â”œâ”€â”€ adversarial_attacks/           # CÃ³digoâ€‘base para geraÃ§Ã£o de ataques
â”œâ”€â”€ attacked_datasets/             # Imagens atacadas geradas
â”œâ”€â”€ images/                        # Resultados e figuras para o relatÃ³rio
â”œâ”€â”€ trained_models/                # Pesos dos modelos treinados
â”œâ”€â”€ .gitignore
â”œâ”€â”€ _mini_XCEPTION.102-0.66.hdf5   # Modelo base prÃ©-treinado (Miniâ€‘Xception)
â”œâ”€â”€ apply_attacks.py               # Gera imagens adversariais em RAFâ€‘DB (e=5)
â”œâ”€â”€ apply_attacks_self_model.py    # Usa o prÃ³prio modelo treinado para criar ataques
â”œâ”€â”€ create_graph_phi.py            # Gera grÃ¡fico da mÃ©trica Ï•
â”œâ”€â”€ evaluate_phi.py                # Calcula a mÃ©trica Ï• de robustez
â”œâ”€â”€ fine_tuning_adversarial.py     # Fineâ€‘tuning com ataques adversariais
â”œâ”€â”€ model.py                       # DefiniÃ§Ã£o do modelo e pipeline de transfer learning
â”œâ”€â”€ phi_results.txt                # Resultados Ï• (modelos limpos)
â”œâ”€â”€ phi_results_adv.txt            # Resultados Ï• (modelos adversariais)
â”œâ”€â”€ test_models_FER_2013.py        # AvaliaÃ§Ã£o em FERâ€‘2013 (modelos base)
â”œâ”€â”€ test_models_RAF.py             # AvaliaÃ§Ã£o em RAFâ€‘DB (modelos base)
â”œâ”€â”€ test_models_RAF_atk.py         # AvaliaÃ§Ã£o em RAFâ€‘DB atacado
â”œâ”€â”€ test_trained_model_FER.py      # AvaliaÃ§Ã£o de modelo treinado em FER
â”œâ”€â”€ test_trained_model_RAF-DB.py   # AvaliaÃ§Ã£o de modelo treinado em RAF
â”œâ”€â”€ test_trained_model_adv_RAF-DB.py # AvaliaÃ§Ã£o de modelo adversarial em RAF
â””â”€â”€ train_model.py                 # Script de treinamento (limpo e adv)
```

## Dados:
- Modelos: Miniâ€‘Xception e variantes fineâ€‘tuned em FERâ€‘2013 e RAF-DB.
- Ataques: FGSM, PGD e DeepFool, comparando forÃ§as (Îµ) diferentes.
- MÃ©trica Ï• (evaluate_phi.py): Percentual de queda de acurÃ¡cia entre modelos limpos e atacados.
- Fineâ€‘tuning Adversarial: EspecializaÃ§Ã£o do modelo usando imagens adversariais durante o treinamento.

## PrÃ©-requisitos
- Python 3.8+
- PyTorch
- OpenCV / Pillow
- NumPy, Pandas, Matplotlib
- tqdm
- (Opcional) CUDA Toolkit para treinamento em GPU
